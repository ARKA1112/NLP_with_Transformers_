{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rIz2WqcoPo6e",
        "outputId": "90059ea5-aaf9-48ac-f335-45fff5f653cc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers[torch] in /usr/local/lib/python3.10/dist-packages (4.30.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (3.12.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.15.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2022.10.31)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2.27.1)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.13.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.3.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (4.65.0)\n",
            "Requirement already satisfied: torch!=1.12.0,>=1.9 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2.0.1+cu118)\n",
            "Requirement already satisfied: accelerate>=0.20.2 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.20.3)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.20.2->transformers[torch]) (5.9.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers[torch]) (2023.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers[torch]) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.9->transformers[torch]) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.9->transformers[torch]) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.9->transformers[torch]) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.9->transformers[torch]) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch!=1.12.0,>=1.9->transformers[torch]) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch!=1.12.0,>=1.9->transformers[torch]) (16.0.5)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (3.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch!=1.12.0,>=1.9->transformers[torch]) (2.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch!=1.12.0,>=1.9->transformers[torch]) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers[torch]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LhFuppbVSaet"
      },
      "outputs": [],
      "source": [
        "!pip install sentencepiece"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NVv0bsf2nz_R"
      },
      "outputs": [],
      "source": [
        "!pip install datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5RrEDR0dPHbg"
      },
      "outputs": [],
      "source": [
        "from transformers import pipeline\n",
        "classifier = pipeline(\"sentiment-analysis\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IM49kZYHPm8G"
      },
      "outputs": [],
      "source": [
        "text = \"\"\"Dear Amazon, last week I ordered an Optimus Prime action figure \\\n",
        "from your online store in Germany. Unfortunately, when I opened the package, \\\n",
        "I discovered to my horror that I had been sent an action figure of Megatron \\\n",
        "instead! As a lifelong enemy of the Decepticons, I hope you can understand my \\\n",
        "dilemma. To resolve the issue, I demand an exchange of Megatron for the \\\n",
        "Optimus Prime figure I ordered. Enclosed are copies of my records concerning \\\n",
        "this purchase. I expect to hear from you soon. Sincerely, Bumblebee.\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MjXYQ357P-OE"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "outputs = classifier(text)\n",
        "pd.DataFrame.from_records(outputs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lAzw-vBsQNuD"
      },
      "source": [
        "Named Entity Recognition(NER)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rgYyXXsJQGkM"
      },
      "outputs": [],
      "source": [
        "\n",
        "ner_tagger = pipeline(\"ner\", aggregation_strategy=\"simple\")\n",
        "outputs = ner_tagger(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S-LDI4TAQZWh"
      },
      "outputs": [],
      "source": [
        "pd.DataFrame.from_records(outputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KLZLIvlYQg16"
      },
      "outputs": [],
      "source": [
        "reader = pipeline(\"question-answering\")\n",
        "question = \"What does the customer want?\"\n",
        "outputs = reader(question=question, context=text)\n",
        "pd.DataFrame.from_records([outputs])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xprv82u8Q_hW"
      },
      "outputs": [],
      "source": [
        "summarizer = pipeline(\"summarization\")\n",
        "outputs = summarizer(text, max_length=65, clean_up_tokenization_spaces=True)\n",
        "print(*outputs[0]['summary_text'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sgtOygmqRouF"
      },
      "outputs": [],
      "source": [
        "translator = pipeline(\"translation_en_to_de\", model=\"t5-small\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xdxms9THoUWq"
      },
      "outputs": [],
      "source": [
        "text = \"Hello world, this is just a demo text\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-vh-zunPSLEt"
      },
      "outputs": [],
      "source": [
        "outputs = translator(text, clean_up_tokenization_spaces=True, min_length=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "33Wk9NcmSTPx"
      },
      "outputs": [],
      "source": [
        "print(outputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y4Zv8eDRpnZd"
      },
      "outputs": [],
      "source": [
        "from datasets import list_datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AZXup3F1pw5I"
      },
      "outputs": [],
      "source": [
        "all_datasets = list_datasets()\n",
        "print(f\"currently there are {len(all_datasets)} in the datasets\")\n",
        "print(f\"the top ten datsets are {all_datasets[:10]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EN676TAxqDeF"
      },
      "outputs": [],
      "source": [
        "print(*all_datasets[23:50],sep=\"\\t\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pjYdRtQ_qnME"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "emotions = load_dataset(\"emotion\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QSLZ3PodsFid"
      },
      "outputs": [],
      "source": [
        "emotions.get('train')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vdu6U3FAsI7j"
      },
      "outputs": [],
      "source": [
        "train_ds=  emotions[\"train\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ypyBr_RE7p3w"
      },
      "outputs": [],
      "source": [
        "train_ds[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7eLkIf677tKk"
      },
      "outputs": [],
      "source": [
        "!pip install pyarrow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ATONkdu68YPx"
      },
      "outputs": [],
      "source": [
        "import pyarrow as pa"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tY0_lzSN8b2v"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "df  = pd.DataFrame(train_ds[:10\n",
        "                      ])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wn6PAo6v8w-F"
      },
      "outputs": [],
      "source": [
        "tables = pa.Table.from_pandas(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BwMhVSw69boF"
      },
      "source": [
        "Clearly pyarrow tables are much more memory efficient"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZfRwYfeF9DCF"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.getsizeof(tables),sys.getsizeof(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-GIoFRJo9Ufo"
      },
      "outputs": [],
      "source": [
        "print(train_ds.features, sep='\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AwYDS9aE9hzB"
      },
      "outputs": [],
      "source": [
        "print(train_ds[:5].items())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RCsMkkHa9xyX"
      },
      "outputs": [],
      "source": [
        "dataset_url = \"https://www.dropbox.com/s/1pzkadrvffbqw6o/train.txt?\"\n",
        "!wget{dataset_url}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DhPJaTwVARO5"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "emotions.set_format(type = 'pandas')\n",
        "df = emotions[\"train\"][:]\n",
        "\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9qq9OLlrAxwX"
      },
      "outputs": [],
      "source": [
        "def label_int2str(row):\n",
        "  return emotions[\"train\"].features[\"label\"].int2str(row)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5522eby-BSTu"
      },
      "outputs": [],
      "source": [
        "df[\"label_name\"] = df[\"label\"].apply(label_int2str)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FuzZcDmZBZ_3"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XTDY1o2ECK5O"
      },
      "outputs": [],
      "source": [
        "df[\"label_name\"].value_counts(ascending=True).plot.barh()\n",
        "plt.title(\"Frequency of Classes\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ly8G0RZtGR1a"
      },
      "source": [
        "How long are out Tweets?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IS86CEFWCW3p"
      },
      "outputs": [],
      "source": [
        "df[\"Words Per Tweet\"] = df[\"text\"].str.split().apply(len)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CZDNcr8HGiQs"
      },
      "outputs": [],
      "source": [
        "df.boxplot(\"Words Per Tweet\", by=\"label_name\", grid=False,showfliers=False,color=\"black\")\n",
        "plt.suptitle(\"\")\n",
        "plt.xlabel(\"\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using pretrained tokenizers"
      ],
      "metadata": {
        "id": "R-3fwxM3r7Pg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fAA1AR6uGi8m"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "model_name = \"facebook/bart-large-mnli\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer"
      ],
      "metadata": {
        "id": "rg2NEjjYsSDs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#We can examine a few attributes of hte tokenizer such as the vocab size\n",
        "\n",
        "tokenizer.vocab_size"
      ],
      "metadata": {
        "id": "dVattjRysThp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.special_tokens_map"
      ],
      "metadata": {
        "id": "zsKnjI5usfm1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.model_max_length"
      ],
      "metadata": {
        "id": "MMNpubGGsmeY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#check the encoding and decoding\n",
        "\n",
        "encoded_str =  tokenizer.encode(\"this is a complicatedtest\")\n",
        "encoded_str"
      ],
      "metadata": {
        "id": "Q59OK2ddssSJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for token in encoded_str:\n",
        "  print(token,tokenizer.decode([token]))"
      ],
      "metadata": {
        "id": "vvABeGeIs3S8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training a Text Classifier"
      ],
      "metadata": {
        "id": "X_wsD5W1tFc0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch"
      ],
      "metadata": {
        "id": "uBwnoAC4warQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install einops"
      ],
      "metadata": {
        "id": "1Dy7buH4w-05"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#Using Pretrained Models\n",
        "\n",
        "from transformers import AutoModel"
      ],
      "metadata": {
        "id": "B8QwND6_s9XU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
      ],
      "metadata": {
        "id": "dNf8PjQDt2SD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Since the model size is really large \n",
        "## We shall prevent RAM overloading"
      ],
      "metadata": {
        "id": "PF-VDOq50kzA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import tempfile\n",
        "model = AutoModel.from_pretrained('facebook/bart-large-mnli')\n",
        "with tempfile.TemporaryDirectory() as tmp_dir:\n",
        "  model.save_pretrained(tmp_dir, max_shard_size= \"124MB\")\n",
        "  new_model = AutoModel.from_pretrained(tmp_dir).to(device)"
      ],
      "metadata": {
        "id": "fYGZm6GVwYzn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Extracting the last hidden states\n",
        "\n",
        "text = \"this is a test\"\n",
        "text_tensor = tokenizer.encode(text, return_tensors=\"pt\").to(device)"
      ],
      "metadata": {
        "id": "SvCTAS4_yXYd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_tensor"
      ],
      "metadata": {
        "id": "EcdeAIGR4D75"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# This output is the hidden state and not any prediction"
      ],
      "metadata": {
        "id": "TYEvq6h66y7z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "output = new_model(text_tensor)"
      ],
      "metadata": {
        "id": "a8ONnnkC4bB5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output.last_hidden_state.shape\n",
        "\n",
        "#([batch_size, n_tokens, hidden_dim])"
      ],
      "metadata": {
        "id": "BQs8x37v4mLQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tokenizing the whole dataset"
      ],
      "metadata": {
        "id": "-lix7mR763Xb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize(batch):\n",
        "  return tokenizer(batch[\"text\"], padding=True, truncation=True)"
      ],
      "metadata": {
        "id": "6nGGL8wo5uTf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#we set the output format of the dataset to pandas so that the accessed data is returned \n",
        "## as a DF. we dont need that now\n",
        "\n",
        "\n",
        "emotions.reset_format()"
      ],
      "metadata": {
        "id": "Wpy2F2qn7BpL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenize(emotions[\"train\"][:3])"
      ],
      "metadata": {
        "id": "ujZAaxw57THQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "emotions_encoded = emotions.map(tokenize, batched=True, batch_size = None)"
      ],
      "metadata": {
        "id": "OxoJbamM7eVV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "emotions_encoded[\"train\"].features['input_ids']"
      ],
      "metadata": {
        "id": "VkqOifOL77Jm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "\n",
        "def forward_pass(batch):\n",
        "  input_ids = torch.tensor(batch[\"input_ids\"]).to(device)\n",
        "  attention_mask = torch.tensor(batch['attention_mask']).to(device)\n",
        "\n",
        "\n",
        "\n",
        "  with torch.no_grad():\n",
        "    last_hidden_state = new_model(input_ids, attention_mask).last_hidden_state\n",
        "    last_hidden_state = last_hidden_state.cpu().numpy()\n",
        "\n",
        "  # Use average of unmasked hidden states for classification\n",
        "\n",
        "\n",
        "  lhs_shape = last_hidden_state.shape\n",
        "  boolean_mask = ~np.array(batch[\"attention_mask\"]).astype(bool)\n",
        "  boolean_mask = np.repeat(boolean_mask, lhs_shape[-1], axis=-1)\n",
        "  boolean_mask = boolean_mask.reshape(lhs_shape)\n",
        "  masked_mean = np.ma.array(last_hidden_state, mask=boolean_mask).mean(axis=1)\n",
        "  batch[\"hidden_state\"] = masked_mean.data\n",
        "  return batch\n",
        "emotions_encoded = emotions_encoded.map(forward_pass, batched=True,\n",
        "batch_size=16)"
      ],
      "metadata": {
        "id": "Y1qPThAW-uqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "emotions_encoded[\"train\"].features"
      ],
      "metadata": {
        "id": "nufiX__uAHXm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create a feature Matrix"
      ],
      "metadata": {
        "id": "RBgSjRbTHEtQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "X_train = np.array(emotions_encoded[\"train\"][\"hidden_state\"])\n",
        "X_valid = np.array(emotions_encoded[\"validation\"]['hidden_state'])\n",
        "\n",
        "y_train = np.array(emotions_encoded['train']['label'])\n",
        "y_valid = np.array(emotions_encoded['validation']['label'])\n"
      ],
      "metadata": {
        "id": "j6m7S854_kct"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape, X_valid.shape"
      ],
      "metadata": {
        "id": "PFDRx7DyUpC6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install umap-learn"
      ],
      "metadata": {
        "id": "-DLZn7LeHo_7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "wZmDQF1YJNYc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from umap import UMAP\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "X_scaled = MinMaxScaler().fit_transform(X_train)\n",
        "mapper = UMAP(n_components=2, metric=\"cosine\").fit(X_scaled)\n",
        "df_emb = pd.DataFrame(mapper.embedding_, columns=['X', 'Y'])\n",
        "df_emb['label'] = y_train\n",
        "df_emb.head()"
      ],
      "metadata": {
        "id": "iKE2phfaIr5y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n"
      ],
      "metadata": {
        "id": "yjEs4dFFRuuw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, axes = plt.subplots(2, 3, figsize=(7,5))\n",
        "axes = axes.flatten()\n",
        "cmaps = [\"Greys\", \"Blues\", \"Oranges\", \"Reds\", \"Purples\", \"Greens\"]\n",
        "labels = emotions[\"train\"].features[\"label\"].names\n",
        "\n",
        "\n",
        "\n",
        "for i, (label, cmap) in enumerate(zip(labels, cmaps)):\n",
        "  df_emb_sub = df_emb.query(f\"label=={i}\")\n",
        "  axes[i].hexbin(df_emb_sub[\"X\"]**0.1, df_emb_sub[\"Y\"], cmap=cmap, gridsize=30, linewidths=(0,))\n",
        "  axes[i].set_title(label)\n",
        "  axes[i].set_xticks([]), axes[i].set_yticks([])\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "\n",
        "\n",
        "#Clearly a strong pattern is visible among the negative as well as the positive emotions"
      ],
      "metadata": {
        "id": "gV1GDqEEI8EZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lets train a simple classifier"
      ],
      "metadata": {
        "id": "Kq2Sfd1jTc_9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from tqdm import tqdm\n",
        "\n",
        "lr_clf  = LogisticRegression(max_iter=3000,verbose=1,n_jobs=10)\n",
        "lr_clf.fit(X_train, y_train)\n",
        "lr_clf.score(X_valid, y_valid)"
      ],
      "metadata": {
        "id": "6Ko76ca1RQZ7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lr_clf.classes_"
      ],
      "metadata": {
        "id": "UCGp0px-apIQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#although 68% is quite low but lets check it with dummy classifier which always chooses\n",
        "#the most frequent class, which yields an accuracy of about 35%\n",
        "\n",
        "\n",
        "from sklearn.dummy import DummyClassifier\n",
        "\n",
        "dummy_clf = DummyClassifier(strategy=\"most_frequent\")\n",
        "dummy_clf.fit(X_train, y_train)\n",
        "dummy_clf.score(X_valid, y_valid)"
      ],
      "metadata": {
        "id": "TFCLuvAYa1sY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import ConfusionMatrixDisplay, confusion_matrix\n",
        "def plot_confusion_matrix(y_preds, y_true, labels):\n",
        "  cm = confusion_matrix(y_true, y_preds, normalize=\"true\")\n",
        "  fig, ax = plt.subplots(figsize=(6, 6))\n",
        "  disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)\n",
        "  disp.plot(cmap=\"Blues\", values_format=\".2f\", ax=ax, colorbar=False)\n",
        "  plt.title(\"Normalized confusion matrix\")\n",
        "  plt.show()  \n",
        "y_preds = lr_clf.predict(X_valid)\n",
        "plot_confusion_matrix(y_preds, y_valid, labels)"
      ],
      "metadata": {
        "id": "gMqBD9OWbM8Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fine-Tuning Transformers"
      ],
      "metadata": {
        "id": "4iVZsl9Ucmwe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Loading a pretrained model\n",
        "\n",
        "from transformers import AutoModelForSequenceClassification\n",
        "import torch"
      ],
      "metadata": {
        "id": "_mOQklpYbVrt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.device"
      ],
      "metadata": {
        "id": "YwQsHGasddou"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "torch.cuda.empty_cache()\n",
        "num_labels = 6\n",
        "model_ckpt = \"facebook/bart-large-mnli\"\n",
        "model = (AutoModelForSequenceClassification.from_pretrained(model_ckpt, num_labels = num_labels,ignore_mismatched_sizes=True).to(device))"
      ],
      "metadata": {
        "id": "9EuCjEGrdG-q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "\n",
        "\n",
        "def compute_metrics(pred):\n",
        "  labels = pred.label_ids\n",
        "  preds = pred.predictions.argmax(-1)\n",
        "  f1 = f1_score(labels, preds, average=\"weighted\")\n",
        "  acc = accuracy_score(labels, preds)\n",
        "  return {\"accuracy\": acc, \"f1\": f1}"
      ],
      "metadata": {
        "id": "ffR02QE3dZtD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import notebook_login"
      ],
      "metadata": {
        "id": "tWQANUbTeqRs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "notebook_login()"
      ],
      "metadata": {
        "id": "ETFFX8hfezDr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#example of TrainingArguments in all its glory\n",
        "\n",
        "model_ckpt = \"facebook/bart_large_mnli\"\n",
        "\n",
        "from transformers import Trainer, TrainingArguments\n",
        "\n",
        "batch_size = 2\n",
        "logging_steps = len(emotions_encoded[\"train\"]) //batch_size\n",
        "\n",
        "model_name = f\"{model_ckpt}_finetuned_emotion\"\n",
        "training_args = TrainingArguments(output_dir = model_name,\n",
        "                                  num_train_epochs=2,\n",
        "                                  learning_rate = 2e-5,\n",
        "                                  per_device_train_batch_size = batch_size,\n",
        "                                  per_device_eval_batch_size=batch_size,\n",
        "                                  weight_decay = 0.01,\n",
        "                                  evaluation_strategy = \"epoch\",\n",
        "                                  disable_tqdm = False,\n",
        "                                  logging_steps = logging_steps,\n",
        "                                  push_to_hub = True,\n",
        "                                  log_level = \"error\"\n",
        "                                  )"
      ],
      "metadata": {
        "id": "rSEbW5NPe1v3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.is_available()\n"
      ],
      "metadata": {
        "id": "eRrIKeyNjRxh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!export 'PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:2'"
      ],
      "metadata": {
        "id": "DcfbFwlXtfUZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from importlib import reload\n",
        "reload(torch)"
      ],
      "metadata": {
        "id": "eptYRvwutq1y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import Trainer\n",
        "\n",
        "trainer = Trainer(model=model, args=training_args,\n",
        "                  compute_metrics = compute_metrics,\n",
        "                  train_dataset = emotions_encoded[\"train\"],\n",
        "                  eval_dataset = emotions_encoded[\"validation\"],\n",
        "                  tokenizer = tokenizer)\n",
        "import gc\n",
        "gc.collect()\n",
        "trainer.train()"
      ],
      "metadata": {
        "id": "T7o85e1CgHfK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jKYZuQXxheyE"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}